{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df6e25e-04c5-4aa2-94ef-7ffa3c9e241a",
   "metadata": {},
   "source": [
    "# Data is data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b6b25-cf0e-4307-afff-41ae499de5fa",
   "metadata": {},
   "source": [
    "fun\n",
    "\n",
    "Inspect the contents of any file on your drive:\n",
    "hexdump some-file-name\n",
    "\n",
    "It shows the actual bytes in the file in hexadecimal notation.\n",
    "Now do this and add the -C switch or argument:\n",
    "hexdump -C some-file-name\n",
    "\n",
    "See what happens? Yes, everything is just binary data; texts, images, video, etc. Does this mean we can play a text document as audio? Sure:\n",
    "aplay some-document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c4a0af-ea7f-4b14-9f5b-049dfeb54686",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting Data (API's, scraping, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4161438-a8cf-41fe-9639-6d153a5adc80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://cdn.sanity.io/images/rzso0e8h/production/da8c3c8105c221ea003ea67057b5a75de819d36d-1920x1280.jpg?w=1920&h=1280&auto=format')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9296ca5a-0d6b-4ed4-9983-b360fdf84510",
   "metadata": {},
   "source": [
    "source: https://labor.org.mx/en/exhibitions/printing-out-the-internet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d506c31-a283-4033-bc7a-76ff650bb24c",
   "metadata": {},
   "source": [
    "https://christopherbaker.net/projects/murmur-study/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a129be-5982-4282-8e82-c0c509a56252",
   "metadata": {},
   "source": [
    "https://twitter.com/everylotla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f22e866-9fad-475b-b7a6-a325eb2db478",
   "metadata": {},
   "source": [
    "### Data sets\n",
    "\n",
    "Need a collection of hugs and kisses, a huge collection of New York Times articles?  \n",
    "https://academictorrents.com\n",
    "\n",
    "Text corpora  \n",
    "https://github.com/dariusk/corpora/tree/master/data\n",
    "\n",
    "Data from around the world  \n",
    "http://datacatalogs.org/\n",
    "\n",
    "Machine learning datasets  \n",
    "https://www.kaggle.com/datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b27e2c-771a-4c5c-808a-be78628f6695",
   "metadata": {
    "tags": []
   },
   "source": [
    "### API's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da76ae1-537d-42ef-9d51-284106cd04ea",
   "metadata": {},
   "source": [
    "#### Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91644c-fa5a-4cf1-9fb7-825b8eb61c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d841271-f16c-4d9f-a927-6718763b3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "'''\n",
    "Install wikipedia first\n",
    "pip install wikipedia\n",
    "\n",
    "Check wikipedia API doc: \n",
    "https://wikipedia.readthedocs.io/en/latest/code.html#api\n",
    "'''\n",
    "\n",
    "# # Search for something\n",
    "# print(wikipedia.search(\"wtf\"))\n",
    "\n",
    "# # Get a summary of page \n",
    "# print(wikipedia.summary(\"random\"))\n",
    "\n",
    "# Get a number of random topics\n",
    "# print(wikipedia.random(pages=4))\n",
    "\n",
    "# # Get a list of image urls of a page\n",
    "print(wikipedia.page(\"random\").images)\n",
    "\n",
    "# # Or just the first image\n",
    "image_url = wikipedia.page(\"random\").images[0]\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(url=image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585ec67f-ead2-4751-adda-3b34ff54b37d",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Wikipedia:Getting_to_Philosophy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cef3a6-112b-45c1-a7da-3b26e4626c49",
   "metadata": {},
   "source": [
    "### Reddit API wrapper (PRAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783a8eb-398e-4124-84c3-8833f3a7bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956b5a7-1ea6-4664-84f6-acfb2a9f9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984aacc-ac73-4141-9c2a-b07fffc876b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INFO: Connecting to reddit...\")\n",
    "\n",
    "# For this api to work you need to first register an account \n",
    "# and fill in the data here\n",
    "\n",
    "r = praw.Reddit(\n",
    "    client_id=\"XWqof3jNyi70G1kOhxfVQg\",\n",
    "    client_secret=\"zCBNFDW_b8EbV1nxRrNzBd0-gWmXvQ\",\n",
    "    user_agent=\"Zealousideal-Iron724\",\n",
    ")\n",
    "\n",
    "if not r.read_only:\n",
    "\n",
    "    raise Exception(\"ERROR: Can't connect to reddit\")\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"INFO: Connected\")\n",
    "    \n",
    "for submission in r.subreddit(\"worldnews\").hot(limit=10):\n",
    "    \n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b60ab-5f93-4bf9-aee5-ff9bc8f4fabb",
   "metadata": {},
   "source": [
    "### Youtube downloader (YT-DLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c99e7-b0c4-41ea-b3ab-7bbc9ae1c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cbe970-ded3-4352-a0bb-370386ae2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir yt_vids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b78d7a-8d8a-48f5-b911-ddec64b311ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "\n",
    "downloads = 'yt_vids'\n",
    "\n",
    "ydl_opts = {\n",
    "    'outtmpl': downloads + '/%(id)s.%(ext)s',\n",
    "    'quiet': False,\n",
    "    'format_sort': ['res:1080', 'ext:mp4:m4a'],\n",
    "    'ignoreerrors': False\n",
    "}\n",
    "\n",
    "URL = 'https://www.youtube.com/watch?v=ysU9hh4pBjc'\n",
    "\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    \n",
    "    info = ydl.extract_info(URL, download=False)\n",
    "    \n",
    "    if info:\n",
    "        width = info.get('width')\n",
    "        height = info.get('height')\n",
    "        duration = info.get('duration')\n",
    "        title = info.get('title')\n",
    "        id = info.get('id')\n",
    "        \n",
    "    \n",
    "    print(\"width: {}, height: {}, duration: {}, title: {}, id: {}\".format(width, height, duration, title, id))\n",
    "    ydl.download(URL)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47deabf-4090-42eb-bf6e-706e9fdbd9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6fc68-a648-4e2a-816f-a7dc679e3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"yt_vids/{}.mp4\".format(id))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10ee5b9-f68f-4680-8dc9-dc4a0eb5efd7",
   "metadata": {},
   "source": [
    "You can find some documentation here: https://github.com/yt-dlp/yt-dlp#embedding-yt-dlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94192dc6-9d28-4224-98ad-a478890d60a9",
   "metadata": {},
   "source": [
    "### Downloading unsecured IP cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec1417-bea5-4a54-829b-9f5ff4929b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://insecam.org/en/view/921591/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ab26b-bd7f-4804-a2e3-05a6ee449202",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f137d11-9848-48fc-8893-eb9d89dbb0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg \n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb4bed-31bd-4e5c-b4c7-01827f2b0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_urls = [\n",
    "    \"http://128.101.85.194/mjpg/video.mjpg\",\n",
    "    \"http://96.91.239.26:1024/mjpg/video.mjpg\",\n",
    "    \"http://84.82.29.229:8080/mjpg/video.mjpg\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2bd39-2472-4388-b249-9d6ea7c809c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_ip(url, dir, idx):\n",
    "\n",
    "    out_path = os.path.join(dir, \"stream_{:03d}\".format(idx))\n",
    "    \n",
    "    process = (\n",
    "        ffmpeg\n",
    "        .input(url)\n",
    "        .output('{}.mkv'.format(out_path), codec=\"copy\")\n",
    "        .overwrite_output()\n",
    "        .run_async(pipe_stdout=True)\n",
    "    )\n",
    "    \n",
    "    print(\"starting capture\")\n",
    "    time.sleep(10)\n",
    "    print(\"ending capture\")\n",
    "    process.stdout.close()\n",
    "    process.kill()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430720da-a275-491e-9ae3-b3afb48ea54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"insecam_streams\"\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    \n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for idx, url in enumerate(cam_urls):\n",
    "\n",
    "    download_from_ip(url, out_dir, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01447d37-cb30-4100-92f9-5264a4265bc2",
   "metadata": {},
   "source": [
    "### Download livstreams with streamlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5344d7-c29b-4d9a-b46f-8cb4388fc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7993c13-61cc-44bc-a4f9-49c3708a7c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlink\n",
    "\n",
    "url = \"https://www.adultswim.com/streams/rick-and-morty\"\n",
    "\n",
    "out_dir = \"streamlink\"\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    \n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "try:\n",
    "    \n",
    "    stream_url = streamlink.streams(url)['best'].url\n",
    "    \n",
    "except:\n",
    "    \n",
    "    print(\"couldn't find stream at {}\".format(url))\n",
    "\n",
    "print(\"found stream at {}\".format(stream_url))\n",
    "\n",
    "streamer = url.split(\"/\")[-1]\n",
    "\n",
    "out_path = os.path.join(out_dir, streamer)\n",
    "\n",
    "process = (\n",
    "    ffmpeg\n",
    "    .input(stream_url)\n",
    "    .output('{}.mkv'.format(out_path), codec=\"copy\")\n",
    "    .overwrite_output()\n",
    "    .run_async(pipe_stdout=True)\n",
    ")\n",
    "\n",
    "print(\"starting capture\")\n",
    "time.sleep(10)\n",
    "print(\"ending capture\")\n",
    "process.stdout.close()\n",
    "process.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558789f-9873-47a8-9d24-a889fd260cf3",
   "metadata": {},
   "source": [
    "You can check all streamlink plugins here: https://streamlink.github.io/plugins.html#plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcccd9c-061b-4783-9cdd-46a6039f9ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b25208-1bca-4120-bf1b-24dfc82136a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41d39b-c74d-4674-a8b6-28fe3d297b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(['San Francisco', 'San Jose', 'Sacramento'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2248853-93a8-41fc-ac47-8221d9744914",
   "metadata": {},
   "source": [
    "`DataFrame` objects can be created by passing a `dict` mapping `string` column names to their respective `Series`. If the `Series` don't match in length, missing values are filled with special [NA/NaN](http://pandas.pydata.org/pandas-docs/stable/missing_data.html) values. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48584f6d-a5a9-43ad-bbcb-f7bc0d708855",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_names = pd.Series(['San Francisco', 'San Jose', 'Sacramento'])\n",
    "population = pd.Series([852469, 1015785, 485199])\n",
    "\n",
    "pd.DataFrame({ 'City name': city_names, 'Population': population })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8cae64-7347-482a-83d0-26e868d068d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c74fa-f4d6-486b-99a4-5bf25f1f4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/unsdsn/world-happiness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b8c79-8ae6-4708-bc46-f64ce17b23c0",
   "metadata": {},
   "source": [
    "The example above used `DataFrame.describe` to show interesting statistics about a `DataFrame`. Another useful function is `DataFrame.head`, which displays the first few records of a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b305da-de2d-4d2a-8c73-93d036e7cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_dataframe = pd.read_csv(\"world-happiness/2015.csv\", sep=\",\")\n",
    "happy_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5e766-9e21-4a22-b624-5b9d823677c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9484fd2b-77c6-4064-a7a0-f9f3536164a7",
   "metadata": {},
   "source": [
    "Another powerful feature of *pandas* is graphing. For example, `DataFrame.hist` lets you quickly study the distribution of values in a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c7555-9e82-409f-abc1-5cb5bd3a1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_dataframe.hist('Happiness Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15992fd-113f-4584-8325-74a3f7ddb292",
   "metadata": {},
   "source": [
    "#### PPRINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9027a3-5938-489a-a6e3-25da44e93ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "json_dict = {\"hyperspace\": {\"constraints\": [], \"design\": [[\"windFarm.windparkSize.k\", \"continuous\", [0, 0, 5]], [\"hydroPlant.primaryControlMax\", \"continuous\", [100, 300]]], \"kpis\": [\"frequency.y\", \"city.load.p[2]\"]}, \"lhc_size\": 10, \"number_of_runs\": 10}\n",
    "\n",
    "formatted_json_str = pprint.pformat(json_dict)\n",
    "print(formatted_json_str)\n",
    "pprint.pprint(json_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
